{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP20BIHcmWygSXVzERL6KY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashweta1/interp/blob/main/cs230_rectifying_facts_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rectifying Factual knowledge through RAG (Retrieval Augmented Generation)\n",
        "\n",
        "This colab uses RAG on wikipedia knowledge dataset, to prepend context to prompts.\n",
        "\n",
        "RAG is used from the library I wrote: git+https://github.com/ashweta1/rag_wiki.git"
      ],
      "metadata": {
        "id": "PM-7oKYqN21I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare environment"
      ],
      "metadata": {
        "id": "GxrQjNdXRQHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# check that colab exists\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "\n",
        "# recreate the local home for this colab run\n",
        "cd /content && rm -rf /content/home && mkdir home && cd home\n",
        "\n",
        "# install the known facts dataset.\n",
        "pip install git+https://github.com/kmeng01/rome.git/tree/main/dsets >> install.log 2>&1\n",
        "\n",
        "# install hugging face datasets library\n",
        "pip install datasets >> install.log 2>&1\n",
        "\n",
        "pip uninstall -y rag_wiki >> install.log 2>&1\n",
        "pip install git+https://github.com/ashweta1/rag_wiki.git >> install.log 2>&1\n",
        "pip list | grep rag_wiki\n",
        "\n",
        "# install latest torch and faiss-gpu\n",
        "pip uninstall -y torch faiss-cpu faiss-gpu >> install.log 2>&1\n",
        "pip install torch faiss-gpu >> install.log 2>&1\n",
        "\n",
        "# pip uninstall -y torch torchaudio torchvision torchtext torchdata faiss-gpu >> install.log 2>&1\n",
        "# pip install torch torchaudio torchvision torchtext torchdata faiss-gpu >> install.log 2>&1"
      ],
      "metadata": {
        "id": "hRdxVUS8PcXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c08e2d5-3575-4425-d569-71f315f73cbd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rag_wiki                           0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ctypes import pythonapi\n",
        "!python --version\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import faiss; print(faiss.__version__)\"\n",
        "!python -c \"import numpy; print(numpy.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsPPMdq7IFbI",
        "outputId": "aab41814-f43f-4db3-9236-d3960d5c5ca9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "2.5.1+cu124\n",
            "1.7.2\n",
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_COLAB = True\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "      device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "      device = torch.device(\"mps\")\n",
        "    else:\n",
        "      device = torch.device(\"cpu\")\n",
        "    print(\"Device = \", device)\n",
        "        # raise Exception(\"Change runtime type to include a GPU.\")\n",
        "\n",
        "    os.chdir(\"/content/home\")\n",
        "    torch.set_grad_enabled(False)  # no model parameter updates\n",
        "\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ],
      "metadata": {
        "id": "7IKG7TkLRT5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6136e5-67bf-43e5-cd24-eb5706a59935"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device =  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IPYTHON magic to automatically reload imported module if they change\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "metadata": {
        "id": "Npy1iKe0R-id"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdO0Ztqp8Ya3",
        "outputId": "46618bab-7668-4efb-8ce8-87049520bbba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 23 08:03:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get wikiqa embeddings loaded\n",
        "import datasets\n",
        "import torch\n",
        "from rag_wiki import rag\n",
        "\n",
        "print(\"torch.cuda.is_available()\", torch.cuda.is_available())\n",
        "print(torch.__version__)\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "# pdframe = rag.load_wikiqa(debug=True)\n",
        "dataset = datasets.load_dataset(\"wiki_qa\", split=\"train\")\n",
        "print(\"Loading dataset...done\")\n",
        "print(\"\")\n",
        "\n",
        "# Preprocess the dataset\n",
        "print(\"Preprocessing dataset...\")\n",
        "index, texts = rag.preprocess_wikiqa(dataset, batch_size=500, debug=True)\n",
        "print(\"Preprocessing dataset...done\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGErrroa5qmZ",
        "outputId": "af33c64f-0409-4e83-f627-0a756dc22056"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.is_available() True\n",
            "2.5.1+cu124\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...done\n",
            "\n",
            "Preprocessing dataset...\n",
            "device =  cuda\n",
            "Getting the model and tokenizer for embeddings...\n",
            "Embedding size =  384\n",
            "Getting the model and tokenizer for embeddings... done\n",
            "Creating FAISS index for storing and searching the embeddings...\n",
            "Moving the index to GPU\n",
            "Creating FAISS index... done\n",
            "Batch 1\n",
            "torch embeddings tensor shape:  torch.Size([17, 384])\n",
            "numpy embeddings shape:  (17, 384)\n",
            "Batch 2\n",
            "torch embeddings tensor shape:  torch.Size([21, 384])\n",
            "numpy embeddings shape:  (21, 384)\n",
            "Batch 3\n",
            "torch embeddings tensor shape:  torch.Size([38, 384])\n",
            "numpy embeddings shape:  (38, 384)\n",
            "Batch 4\n",
            "torch embeddings tensor shape:  torch.Size([18, 384])\n",
            "numpy embeddings shape:  (18, 384)\n",
            "Batch 5\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 6\n",
            "torch embeddings tensor shape:  torch.Size([20, 384])\n",
            "numpy embeddings shape:  (20, 384)\n",
            "Batch 7\n",
            "torch embeddings tensor shape:  torch.Size([20, 384])\n",
            "numpy embeddings shape:  (20, 384)\n",
            "Batch 8\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 9\n",
            "torch embeddings tensor shape:  torch.Size([26, 384])\n",
            "numpy embeddings shape:  (26, 384)\n",
            "Batch 10\n",
            "torch embeddings tensor shape:  torch.Size([18, 384])\n",
            "numpy embeddings shape:  (18, 384)\n",
            "Batch 11\n",
            "torch embeddings tensor shape:  torch.Size([31, 384])\n",
            "numpy embeddings shape:  (31, 384)\n",
            "Batch 12\n",
            "torch embeddings tensor shape:  torch.Size([22, 384])\n",
            "numpy embeddings shape:  (22, 384)\n",
            "Batch 13\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 14\n",
            "torch embeddings tensor shape:  torch.Size([22, 384])\n",
            "numpy embeddings shape:  (22, 384)\n",
            "Batch 15\n",
            "torch embeddings tensor shape:  torch.Size([27, 384])\n",
            "numpy embeddings shape:  (27, 384)\n",
            "Batch 16\n",
            "torch embeddings tensor shape:  torch.Size([38, 384])\n",
            "numpy embeddings shape:  (38, 384)\n",
            "Batch 17\n",
            "torch embeddings tensor shape:  torch.Size([26, 384])\n",
            "numpy embeddings shape:  (26, 384)\n",
            "Batch 18\n",
            "torch embeddings tensor shape:  torch.Size([29, 384])\n",
            "numpy embeddings shape:  (29, 384)\n",
            "Batch 19\n",
            "torch embeddings tensor shape:  torch.Size([27, 384])\n",
            "numpy embeddings shape:  (27, 384)\n",
            "Batch 20\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 21\n",
            "torch embeddings tensor shape:  torch.Size([32, 384])\n",
            "numpy embeddings shape:  (32, 384)\n",
            "Batch 22\n",
            "torch embeddings tensor shape:  torch.Size([25, 384])\n",
            "numpy embeddings shape:  (25, 384)\n",
            "Batch 23\n",
            "torch embeddings tensor shape:  torch.Size([26, 384])\n",
            "numpy embeddings shape:  (26, 384)\n",
            "Batch 24\n",
            "torch embeddings tensor shape:  torch.Size([28, 384])\n",
            "numpy embeddings shape:  (28, 384)\n",
            "Batch 25\n",
            "torch embeddings tensor shape:  torch.Size([36, 384])\n",
            "numpy embeddings shape:  (36, 384)\n",
            "Batch 26\n",
            "torch embeddings tensor shape:  torch.Size([27, 384])\n",
            "numpy embeddings shape:  (27, 384)\n",
            "Batch 27\n",
            "torch embeddings tensor shape:  torch.Size([22, 384])\n",
            "numpy embeddings shape:  (22, 384)\n",
            "Batch 28\n",
            "torch embeddings tensor shape:  torch.Size([40, 384])\n",
            "numpy embeddings shape:  (40, 384)\n",
            "Batch 29\n",
            "torch embeddings tensor shape:  torch.Size([38, 384])\n",
            "numpy embeddings shape:  (38, 384)\n",
            "Batch 30\n",
            "torch embeddings tensor shape:  torch.Size([32, 384])\n",
            "numpy embeddings shape:  (32, 384)\n",
            "Batch 31\n",
            "torch embeddings tensor shape:  torch.Size([31, 384])\n",
            "numpy embeddings shape:  (31, 384)\n",
            "Batch 32\n",
            "torch embeddings tensor shape:  torch.Size([29, 384])\n",
            "numpy embeddings shape:  (29, 384)\n",
            "Batch 33\n",
            "torch embeddings tensor shape:  torch.Size([25, 384])\n",
            "numpy embeddings shape:  (25, 384)\n",
            "Batch 34\n",
            "torch embeddings tensor shape:  torch.Size([21, 384])\n",
            "numpy embeddings shape:  (21, 384)\n",
            "Batch 35\n",
            "torch embeddings tensor shape:  torch.Size([23, 384])\n",
            "numpy embeddings shape:  (23, 384)\n",
            "Batch 36\n",
            "torch embeddings tensor shape:  torch.Size([16, 384])\n",
            "numpy embeddings shape:  (16, 384)\n",
            "Batch 37\n",
            "torch embeddings tensor shape:  torch.Size([15, 384])\n",
            "numpy embeddings shape:  (15, 384)\n",
            "Batch 38\n",
            "torch embeddings tensor shape:  torch.Size([17, 384])\n",
            "numpy embeddings shape:  (17, 384)\n",
            "Batch 39\n",
            "torch embeddings tensor shape:  torch.Size([18, 384])\n",
            "numpy embeddings shape:  (18, 384)\n",
            "Batch 40\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 41\n",
            "torch embeddings tensor shape:  torch.Size([19, 384])\n",
            "numpy embeddings shape:  (19, 384)\n",
            "Length of texts =  1040\n",
            "Preprocessing dataset...done\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get wikipedia embeddings loaded\n",
        "import torch\n",
        "from rag_wiki import rag\n",
        "\n",
        "print(\"torch.cuda.is_available()\", torch.cuda.is_available())\n",
        "print(torch.__version__)\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "dataset = rag.load_wiki_dataset(num_examples=1000, debug=True)\n",
        "print(\"Loading dataset...done\")\n",
        "print(\"\")\n",
        "\n",
        "# Preprocess the dataset\n",
        "print(\"Preprocessing dataset...\")\n",
        "index, texts = rag.preprocess(dataset, batch_size=200, debug=True)\n",
        "print(\"Preprocessing dataset...done\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "d6BGvIuzwVI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yIfTxzTdSlqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "def get_gpt2_model(device='cuda'):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2-medium', pad_token_id=tokenizer.eos_token_id).to(device)\n",
        "    return model, tokenizer\n",
        "model, tokenizer = get_gpt2_model()"
      ],
      "metadata": {
        "id": "q6bOKGbsGMJD"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, prompt, max_length=50, device='cuda'):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    outputs = model.generate(input_ids.to(device),\n",
        "                             max_length=10000,\n",
        "                             do_sample=True,\n",
        "                             num_beams=3,\n",
        "                             temperature=0.7,\n",
        "                             no_repeat_ngram_size=2,\n",
        "                             early_stopping=True,\n",
        "                             eos_token_id=tokenizer.encode(\".\")[0])\n",
        "\n",
        "    # Decode the generated sequence back to text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "shjK3eEiGMlO"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the index and retrieve relevant texts\n",
        "TOP_K_TEXTS = 2\n",
        "prompts = [\"What is the capital of India?\",\n",
        "           \"Who is the president of the United States?\",\n",
        "           \"What is the population of China?\",\n",
        "           \"The captial of France is \",\n",
        "           \"Where is the Eiffel Tower located?\"]\n",
        "prompts = [\"how long was i love lucy on the air\",\n",
        "           \"how did apollo creed die\",\n",
        "           \"how much is 1 tablespoon of water\",\n",
        "           \"how much are the harry potter movies worth\"]\n",
        "\n",
        "print(\"Retrieving relevant texts...\")\n",
        "print(\"Length of texts = \", len(texts))\n",
        "retrieved_texts = rag.retrieve(prompts, index, texts, top_k=TOP_K_TEXTS, debug=False)\n",
        "print(\"Retrieving relevant texts...done\")\n",
        "print(\"\")\n",
        "\n",
        "for p, ts in zip(prompts, retrieved_texts):\n",
        "    print(f\"Prompt: {p}\")\n",
        "    print(f\"Retrieved texts: {len(ts)}\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJRQO7v0107e",
        "outputId": "c3b0d44d-3354-42f2-cec6-316a8a7408e8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving relevant texts...\n",
            "Length of texts =  1040\n",
            "Retrieving relevant texts...done\n",
            "\n",
            "Prompt: how long was i love lucy on the air\n",
            "Retrieved texts: 2\n",
            "\n",
            "Prompt: how did apollo creed die\n",
            "Retrieved texts: 2\n",
            "\n",
            "Prompt: how much is 1 tablespoon of water\n",
            "Retrieved texts: 2\n",
            "\n",
            "Prompt: how much are the harry potter movies worth\n",
            "Retrieved texts: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in prompts:\n",
        "    print(\"Prompt: \", p)\n",
        "    print(\"----\")\n",
        "    print(generate_text(model, tokenizer, p))\n",
        "    print(\"=====\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "yVgEXTtgGdIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655b1bea-d565-43d2-fcdf-10590ff59356"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:  how long was i love lucy on the air\n",
            "----\n",
            "how long was i love lucy on the air, t on a on t the e on n on d on on w on o on r on g on h on e the on b on l on i on s on y on , on air.\n",
            "=====\n",
            "\n",
            "Prompt:  how did apollo creed die\n",
            "----\n",
            "how did apollo creed die out?\"\n",
            "\n",
            "\"No, it didn't.\n",
            "=====\n",
            "\n",
            "Prompt:  how much is 1 tablespoon of water\n",
            "----\n",
            "how much is 1 tablespoon of water and 1/2 teaspoon of sugar in a large bowl?\n",
            "\n",
            "The answer is no.\n",
            "=====\n",
            "\n",
            "Prompt:  how much are the harry potter movies worth\n",
            "----\n",
            "how much are the harry potter movies worth?\"\n",
            "\n",
            "\"No, I don't think so.\n",
            "=====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepend = \"Based on the information provided, answer the question concisely. Do not repeat the prompt.\"\n",
        "section1 = \"[INFO]\"\n",
        "section2 = \"[QUESTION]\"\n",
        "section3 = \"[ANSWER]\"\n",
        "qa_prompt_with_context = [prepend + \"\\n\" + section1 + \"\\n\" + \"\\n\".join(ts)[:1000] + \"\\n\" + section2 + \"\\n\" + p + \"\\n\" + section3 + \"\\n\" for p, ts in zip(prompts, retrieved_texts)]\n",
        "\n",
        "for p in qa_prompt_with_context:\n",
        "    print(\"Prompt: \", p)\n",
        "    print(\"----\")\n",
        "    print(generate_text(model, tokenizer, p))\n",
        "    print(\"=====\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv7BIwqU9T5O",
        "outputId": "4941fa31-3b3f-4bd8-83bf-94af09ffe088"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC television sketch comedy series Saturday Night Live (SNL) from 1986 to 1992.\n",
            "who played guitar on the kiss album, creatures of the night It is also the band's last album recorded with Ace Frehley credited as an official member (until 1998's Psycho Circus ), and its first album with Vinnie Vincent as the initially uncredited lead guitarist (Vincent would later be credited, but not featured pictorially on the cover, of 1985's reissue of the album ).\n",
            "[QUESTION]\n",
            "how long was i love lucy on the air\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC television sketch comedy series Saturday Night Live (SNL) from 1986 to 1992.\n",
            "who played guitar on the kiss album, creatures of the night It is also the band's last album recorded with Ace Frehley credited as an official member (until 1998's Psycho Circus ), and its first album with Vinnie Vincent as the initially uncredited lead guitarist (Vincent would later be credited, but not featured pictorially on the cover, of 1985's reissue of the album ).\n",
            "[QUESTION]\n",
            "how long was i love lucy on the air\n",
            "[ANSWER]\n",
            "I love it so much that I can't remember.\n",
            "=====\n",
            "\n",
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\n",
            "how was the moon formed Although there have been several hypotheses for its origin in the past, the current most widely accepted explanation is that the Moon formed from the debris left over after a giant impact between Earth and a Mars -sized body.\n",
            "[QUESTION]\n",
            "how did apollo creed die\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\n",
            "how was the moon formed Although there have been several hypotheses for its origin in the past, the current most widely accepted explanation is that the Moon formed from the debris left over after a giant impact between Earth and a Mars -sized body.\n",
            "[QUESTION]\n",
            "how did apollo creed die\n",
            "[ANSWER]\n",
            "The Apollo Creed was written by a man named Phil Plait.\n",
            "=====\n",
            "\n",
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\n",
            "how much is 1 tablespoon of water In the USA one tablespoon (measurement unit) is approximately 15 mL; the capacity of an actual tablespoon (dining utensil) ranges from 7 mL to 14 mL.\n",
            "[QUESTION]\n",
            "how much is 1 tablespoon of water\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\n",
            "how much is 1 tablespoon of water In the USA one tablespoon (measurement unit) is approximately 15 mL; the capacity of an actual tablespoon (dining utensil) ranges from 7 mL to 14 mL.\n",
            "[QUESTION]\n",
            "how much is 1 tablespoon of water\n",
            "[ANSWER]\n",
            "How much water is in a cup of coffee? How much does it take to make 1/2 cup (1 cup) of tea?\n",
            "What is the amount of sugar in the cup? What does the sugar taste like? Do you know how much sugar you need to drink to get the correct amount? If you do not know the answer to this question, then you are missing out on something important.\n",
            "=====\n",
            "\n",
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\n",
            "who is the actor that plays harry potter Daniel Radcliffe , who portrays Harry Potter , has been the icon of the film series since the release of the first film in 2001.\n",
            "[QUESTION]\n",
            "how much are the harry potter movies worth\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\n",
            "who is the actor that plays harry potter Daniel Radcliffe , who portrays Harry Potter , has been the icon of the film series since the release of the first film in 2001.\n",
            "[QUESTION]\n",
            "how much are the harry potter movies worth\n",
            "[ANSWER]\n",
            "The series is based on a series of novels written by the author, and is set in the 1950s and 1960s.\n",
            "=====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_with_context = [\" \".join(ts)[:200] + \"\\n\" + p for p, ts in zip(prompts, retrieved_texts)]\n",
        "\n",
        "for p in prompt_with_context:\n",
        "    print(\"Prompt: \", p)\n",
        "    print(\"----\")\n",
        "    print(generate_text(model, tokenizer, p))\n",
        "    print(\"=====\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQVZuyLqGHHq",
        "outputId": "c700eee2-b3c4-4c3f-b141-167802ee62b9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:  who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC t\n",
            "how long was i love lucy on the air\n",
            "----\n",
            "who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC t\n",
            "how long was i love lucy on the air?\n",
            "\n",
            "I love her so much.\n",
            "=====\n",
            "\n",
            "Prompt:  how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth. how was the moon formed Although there have been several hypotheses for its origin in\n",
            "how did apollo creed die\n",
            "----\n",
            "how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth. how was the moon formed Although there have been several hypotheses for its origin in\n",
            "how did apollo creed die out The moon is believed to be the result of a meteorite falling from the sky.\n",
            "=====\n",
            "\n",
            "Prompt:  how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL. how much is 1 tablespoon of water In the USA one tablespoon (measurement unit) is approximately 15 mL; the capacity of \n",
            "how much is 1 tablespoon of water\n",
            "----\n",
            "how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL. how much is 1 tablespoon of water In the USA one tablespoon (measurement unit) is approximately 15 mL; the capacity of \n",
            "how much is 1 tablespoon of water in the U.\n",
            "=====\n",
            "\n",
            "Prompt:  how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion. who is the actor that plays harry potter Da\n",
            "how much are the harry potter movies worth\n",
            "----\n",
            "how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion. who is the actor that plays harry potter Da\n",
            "how much are the harry potter movies worth\n",
            "\n",
            "Harry Potter and the Deathly Hallows Part 2: The End of the World is based on the novel by J.\n",
            "=====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEw7FK9o8gYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def evaluate_dataset(dataset, use_rag=False, top_k_texts=1):\n",
        "  smoothing = SmoothingFunction()\n",
        "  total_bleu = 0\n",
        "  total = 0\n",
        "\n",
        "  for d in dataset:\n",
        "    if d['label'] != 1:\n",
        "      continue\n",
        "\n",
        "    question = d['question']\n",
        "    expected_answer = d['answer']\n",
        "\n",
        "    if use_rag:\n",
        "      retrieved_texts = rag.retrieve([question], index, texts, top_k=top_k_texts, debug=False)\n",
        "      question = [\" \".join(ts)[:1000] + \"\\n\" + question for ts in retrieved_texts][0]\n",
        "\n",
        "    answer = generate_text(model, tokenizer, question)\n",
        "\n",
        "    # remove the question prefix from the generated answer and then compare.\n",
        "    answer = answer.replace(question, '')\n",
        "    # replace special characters like ?,\n",
        "    answer = answer.replace('?', '')\n",
        "    # remove leading and trailing spaces\n",
        "    answer = answer.strip()\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu = sentence_bleu([expected_answer],\n",
        "                         answer,\n",
        "                         weights=[0.5, 0.5, 0.5, 0],\n",
        "                         smoothing_function=smoothing.method1)\n",
        "    if bleu > 0.3:\n",
        "      print(\"Question: \", question)\n",
        "      print(\"Expected Answer: \", expected_answer)\n",
        "      print(\"Generated answer: \", answer)\n",
        "      print(\"BLEU = \", bleu)\n",
        "      print(\"\")\n",
        "\n",
        "    total_bleu += bleu\n",
        "    total += 1\n",
        "\n",
        "  average_bleu = total_bleu / total\n",
        "  print(\"Average Bleu = \", average_bleu)\n",
        ""
      ],
      "metadata": {
        "id": "wiIJ5mBJIjOK"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate wikiqa validation set, with and without RAG from train.\n",
        "validation_dataset = datasets.load_dataset(\"wiki_qa\", split=\"validation\")\n",
        "evaluate_dataset(validation_dataset, use_rag=False)\n"
      ],
      "metadata": {
        "id": "4S4t6V62N9Xq",
        "outputId": "36628515-e358-4d86-ea2a-076d525678fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  what county is Holly Ridge nc in?\n",
            "Expected Answer:  Holly Ridge is a town in Onslow County , North Carolina , United States .\n",
            "Generated answer:  Holly Ridge is located in the county of North Carolina.\n",
            "BLEU =  0.4975020291498672\n",
            "\n",
            "Question:  What are context effects of memory?\n",
            "Expected Answer:  Context-dependent memory refers to improved recall of specific episodes or information when the context present at encoding and retrieval are the same.\n",
            "Generated answer:  Context effects are the effects that happen when you're looking at something from different perspectives at the same time.\n",
            "BLEU =  0.3416568073458293\n",
            "\n",
            "Question:  what is stepwise linear regression\n",
            "Expected Answer:  In statistics , stepwise regression includes regression models in which the choice of predictive variables is carried out by an automatic procedure.\n",
            "Generated answer:  Stepwise Linear Regression (SLR) is a statistical method that can be used to predict the outcome of a trial.\n",
            "BLEU =  0.3242583405102552\n",
            "\n",
            "Question:  what is linkedin used for\n",
            "Expected Answer:  LinkedIn () is a social networking website for people in professional occupations.\n",
            "Generated answer:  Linkedin is a social networking site that allows you to connect with people from around the world.\n",
            "BLEU =  0.37432877019101857\n",
            "\n",
            "Question:  What is the the North American Free Trade Agreement?\n",
            "Expected Answer:  The North American Free Trade Agreement (NAFTA) is an agreement signed by Canada , Mexico , and the United States , creating a trilateral trade bloc in North America .\n",
            "Generated answer:  NAFTA is a free trade agreement between the United States, Canada, Mexico, and the European Union.\n",
            "BLEU =  0.32467487637091885\n",
            "\n",
            "Average Bleu =  0.08979315762967248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = datasets.load_dataset(\"wiki_qa\", split=\"validation\")\n",
        "evaluate_dataset(validation_dataset, use_rag=True)"
      ],
      "metadata": {
        "id": "kPcZ8YjQP-Xd",
        "outputId": "19931949-0450-421e-efc6-c3e0c4159889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  what causes the seasons Seasons result from the yearly revolution of the Earth around the Sun and the tilt of the Earth's axis relative to the plane of revolution.\n",
            "what forms seasons\n",
            "Expected Answer:  It is the tilt of the Earth that causes the Sun to be higher in the sky during the summer months which increases the solar flux .\n",
            "Generated answer:  Season is the term used to refer to a period of time during which there is a change in the amount of sunlight that falls on Earth.\n",
            "BLEU =  0.44678838043004065\n",
            "\n",
            "Question:  what is a millwright worker A millwright is a craftsman or tradesman engaged with the construction and maintenance of machinery .\n",
            "what was the steelworkers strike\n",
            "Expected Answer:  The Steel Strike of 1919 was an attempt by the weakened Amalgamated Association of Iron, Steel and Tin Workers (the AA) to organize the United States steel industry in the wake of World War I .\n",
            "Generated answer:  A steelworker strike was a general strike of workers in the United States in response to the introduction of steel in steel mills.\n",
            "BLEU =  0.3526251359543434\n",
            "\n",
            "Question:  when does air bag deploy It is an occupant restraint system consisting of a flexible fabric envelope or cushion designed to inflate rapidly during an automobile collision .\n",
            "what is the cabin pressure of us airlines\n",
            "Expected Answer:  Cabin pressurization is used to create a safe and comfortable environment for aircraft passengers and crew flying at high altitude by pumping conditioned air into the cabin .\n",
            "Generated answer:  and what is it like in air bags\n",
            "air bags are used to protect passengers from the impact of an impact, but they are also used in a number of other ways.\n",
            "BLEU =  0.3025793765870281\n",
            "\n",
            "Question:  Who is the rap singer in right round with kesha in the background? *(dancer)* \"Right Round\" is a song performed by American rapper Flo Rida , released as the lead single from his second studio album, R.O.O.T.S. (2009).\n",
            "what is stepwise linear regression\n",
            "Expected Answer:  In statistics , stepwise regression includes regression models in which the choice of predictive variables is carried out by an automatic procedure.\n",
            "Generated answer:  and why is it useful\n",
            "Stepwise Linear Regression (SLR) is one of the most popular statistical methods used in statistics.\n",
            "BLEU =  0.33073543830851637\n",
            "\n",
            "Question:  what city is oregon state university in Oregon State University (OSU) is a coeducational , public research university located in Corvallis , Oregon , United States .\n",
            "what is oregon institute of technology like\n",
            "Expected Answer:  Oregon Institute of Technology, also known as Oregon Tech or OIT, is one of seven Universities in the Oregon University System , and the only public institute of technology in the Pacific Northwest .\n",
            "Generated answer:  what is the name of the university is located on the west coast of Oregon in the state of Washington . what university do you go to if you want to learn more about the history of science and technology.\n",
            "BLEU =  0.375249289092052\n",
            "\n",
            "Question:  how many amendments in the US constitution Twenty-seven amendments have been ratified since the original signing of the Constitution, the first ten of which are known collectively as the Bill of Rights .\n",
            "When was 27th amendment proposed\n",
            "Expected Answer:  It was submitted to the states for ratification in 1789 and was adopted in 1992.\n",
            "Generated answer:  It was proposed in 1789, and ratified by the states in 1868.\n",
            "BLEU =  0.4508007965731791\n",
            "\n",
            "Average Bleu =  0.1389066671369495\n"
          ]
        }
      ]
    }
  ]
}