{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNx1yCsx1aY0tbAsnr7XVUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashweta1/interp/blob/main/cs230_rectifying_facts_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rectifying Factual knowledge through RAG (Retrieval Augmented Generation)\n",
        "\n",
        "This colab uses RAG on wikipedia knowledge dataset, to prepend context to prompts.\n",
        "\n",
        "RAG is used from the library I wrote: git+https://github.com/ashweta1/rag_wiki.git"
      ],
      "metadata": {
        "id": "PM-7oKYqN21I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare environment"
      ],
      "metadata": {
        "id": "GxrQjNdXRQHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# check that colab exists\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "\n",
        "# recreate the local home for this colab run\n",
        "cd /content && rm -rf /content/home && mkdir home && cd home\n",
        "\n",
        "# install the known facts dataset.\n",
        "pip install git+https://github.com/kmeng01/rome.git/tree/main/dsets >> install.log 2>&1\n",
        "\n",
        "# install hugging face datasets library\n",
        "pip install datasets >> install.log 2>&1\n",
        "\n",
        "pip uninstall -y rag_wiki >> install.log 2>&1\n",
        "pip install git+https://github.com/ashweta1/rag_wiki.git >> install.log 2>&1\n",
        "pip list | grep rag_wiki\n",
        "\n",
        "# install latest torch and faiss-gpu\n",
        "pip uninstall -y torch faiss-cpu faiss-gpu >> install.log 2>&1\n",
        "pip install torch faiss-gpu >> install.log 2>&1\n",
        "\n",
        "# pip uninstall -y torch torchaudio torchvision torchtext torchdata faiss-gpu >> install.log 2>&1\n",
        "# pip install torch torchaudio torchvision torchtext torchdata faiss-gpu >> install.log 2>&1"
      ],
      "metadata": {
        "id": "hRdxVUS8PcXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c08e2d5-3575-4425-d569-71f315f73cbd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rag_wiki                           0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ctypes import pythonapi\n",
        "!python --version\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import faiss; print(faiss.__version__)\"\n",
        "!python -c \"import numpy; print(numpy.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsPPMdq7IFbI",
        "outputId": "aab41814-f43f-4db3-9236-d3960d5c5ca9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "2.5.1+cu124\n",
            "1.7.2\n",
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_COLAB = True\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "      device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "      device = torch.device(\"mps\")\n",
        "    else:\n",
        "      device = torch.device(\"cpu\")\n",
        "    print(\"Device = \", device)\n",
        "        # raise Exception(\"Change runtime type to include a GPU.\")\n",
        "\n",
        "    os.chdir(\"/content/home\")\n",
        "    torch.set_grad_enabled(False)  # no model parameter updates\n",
        "\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ],
      "metadata": {
        "id": "7IKG7TkLRT5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6136e5-67bf-43e5-cd24-eb5706a59935"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device =  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IPYTHON magic to automatically reload imported module if they change\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "metadata": {
        "id": "Npy1iKe0R-id"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdO0Ztqp8Ya3",
        "outputId": "46618bab-7668-4efb-8ce8-87049520bbba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 23 08:03:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get wikiqa embeddings loaded\n",
        "import datasets\n",
        "import torch\n",
        "from rag_wiki import rag\n",
        "\n",
        "print(\"torch.cuda.is_available()\", torch.cuda.is_available())\n",
        "print(torch.__version__)\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "# pdframe = rag.load_wikiqa(debug=True)\n",
        "dataset = datasets.load_dataset(\"wiki_qa\", split=\"train\")\n",
        "print(\"Loading dataset...done\")\n",
        "print(\"\")\n",
        "\n",
        "# Preprocess the dataset\n",
        "print(\"Preprocessing dataset...\")\n",
        "index, texts = rag.preprocess_wikiqa(dataset, batch_size=500, debug=True)\n",
        "print(\"Preprocessing dataset...done\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "OGErrroa5qmZ",
        "outputId": "af33c64f-0409-4e83-f627-0a756dc22056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.is_available() True\n",
            "2.5.1+cu124\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...done\n",
            "\n",
            "Preprocessing dataset...\n",
            "device =  cuda\n",
            "Getting the model and tokenizer for embeddings...\n",
            "Embedding size =  384\n",
            "Getting the model and tokenizer for embeddings... done\n",
            "Creating FAISS index for storing and searching the embeddings...\n",
            "Moving the index to GPU\n",
            "Creating FAISS index... done\n",
            "Batch 1\n",
            "torch embeddings tensor shape:  torch.Size([17, 384])\n",
            "numpy embeddings shape:  (17, 384)\n",
            "Batch 2\n",
            "torch embeddings tensor shape:  torch.Size([21, 384])\n",
            "numpy embeddings shape:  (21, 384)\n",
            "Batch 3\n",
            "torch embeddings tensor shape:  torch.Size([38, 384])\n",
            "numpy embeddings shape:  (38, 384)\n",
            "Batch 4\n",
            "torch embeddings tensor shape:  torch.Size([18, 384])\n",
            "numpy embeddings shape:  (18, 384)\n",
            "Batch 5\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 6\n",
            "torch embeddings tensor shape:  torch.Size([20, 384])\n",
            "numpy embeddings shape:  (20, 384)\n",
            "Batch 7\n",
            "torch embeddings tensor shape:  torch.Size([20, 384])\n",
            "numpy embeddings shape:  (20, 384)\n",
            "Batch 8\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 9\n",
            "torch embeddings tensor shape:  torch.Size([26, 384])\n",
            "numpy embeddings shape:  (26, 384)\n",
            "Batch 10\n",
            "torch embeddings tensor shape:  torch.Size([18, 384])\n",
            "numpy embeddings shape:  (18, 384)\n",
            "Batch 11\n",
            "torch embeddings tensor shape:  torch.Size([31, 384])\n",
            "numpy embeddings shape:  (31, 384)\n",
            "Batch 12\n",
            "torch embeddings tensor shape:  torch.Size([22, 384])\n",
            "numpy embeddings shape:  (22, 384)\n",
            "Batch 13\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 14\n",
            "torch embeddings tensor shape:  torch.Size([22, 384])\n",
            "numpy embeddings shape:  (22, 384)\n",
            "Batch 15\n",
            "torch embeddings tensor shape:  torch.Size([27, 384])\n",
            "numpy embeddings shape:  (27, 384)\n",
            "Batch 16\n",
            "torch embeddings tensor shape:  torch.Size([38, 384])\n",
            "numpy embeddings shape:  (38, 384)\n",
            "Batch 17\n",
            "torch embeddings tensor shape:  torch.Size([26, 384])\n",
            "numpy embeddings shape:  (26, 384)\n",
            "Batch 18\n",
            "torch embeddings tensor shape:  torch.Size([29, 384])\n",
            "numpy embeddings shape:  (29, 384)\n",
            "Batch 19\n",
            "torch embeddings tensor shape:  torch.Size([27, 384])\n",
            "numpy embeddings shape:  (27, 384)\n",
            "Batch 20\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 21\n",
            "torch embeddings tensor shape:  torch.Size([32, 384])\n",
            "numpy embeddings shape:  (32, 384)\n",
            "Batch 22\n",
            "torch embeddings tensor shape:  torch.Size([25, 384])\n",
            "numpy embeddings shape:  (25, 384)\n",
            "Batch 23\n",
            "torch embeddings tensor shape:  torch.Size([26, 384])\n",
            "numpy embeddings shape:  (26, 384)\n",
            "Batch 24\n",
            "torch embeddings tensor shape:  torch.Size([28, 384])\n",
            "numpy embeddings shape:  (28, 384)\n",
            "Batch 25\n",
            "torch embeddings tensor shape:  torch.Size([36, 384])\n",
            "numpy embeddings shape:  (36, 384)\n",
            "Batch 26\n",
            "torch embeddings tensor shape:  torch.Size([27, 384])\n",
            "numpy embeddings shape:  (27, 384)\n",
            "Batch 27\n",
            "torch embeddings tensor shape:  torch.Size([22, 384])\n",
            "numpy embeddings shape:  (22, 384)\n",
            "Batch 28\n",
            "torch embeddings tensor shape:  torch.Size([40, 384])\n",
            "numpy embeddings shape:  (40, 384)\n",
            "Batch 29\n",
            "torch embeddings tensor shape:  torch.Size([38, 384])\n",
            "numpy embeddings shape:  (38, 384)\n",
            "Batch 30\n",
            "torch embeddings tensor shape:  torch.Size([32, 384])\n",
            "numpy embeddings shape:  (32, 384)\n",
            "Batch 31\n",
            "torch embeddings tensor shape:  torch.Size([31, 384])\n",
            "numpy embeddings shape:  (31, 384)\n",
            "Batch 32\n",
            "torch embeddings tensor shape:  torch.Size([29, 384])\n",
            "numpy embeddings shape:  (29, 384)\n",
            "Batch 33\n",
            "torch embeddings tensor shape:  torch.Size([25, 384])\n",
            "numpy embeddings shape:  (25, 384)\n",
            "Batch 34\n",
            "torch embeddings tensor shape:  torch.Size([21, 384])\n",
            "numpy embeddings shape:  (21, 384)\n",
            "Batch 35\n",
            "torch embeddings tensor shape:  torch.Size([23, 384])\n",
            "numpy embeddings shape:  (23, 384)\n",
            "Batch 36\n",
            "torch embeddings tensor shape:  torch.Size([16, 384])\n",
            "numpy embeddings shape:  (16, 384)\n",
            "Batch 37\n",
            "torch embeddings tensor shape:  torch.Size([15, 384])\n",
            "numpy embeddings shape:  (15, 384)\n",
            "Batch 38\n",
            "torch embeddings tensor shape:  torch.Size([17, 384])\n",
            "numpy embeddings shape:  (17, 384)\n",
            "Batch 39\n",
            "torch embeddings tensor shape:  torch.Size([18, 384])\n",
            "numpy embeddings shape:  (18, 384)\n",
            "Batch 40\n",
            "torch embeddings tensor shape:  torch.Size([24, 384])\n",
            "numpy embeddings shape:  (24, 384)\n",
            "Batch 41\n",
            "torch embeddings tensor shape:  torch.Size([19, 384])\n",
            "numpy embeddings shape:  (19, 384)\n",
            "Length of texts =  1040\n",
            "Preprocessing dataset...done\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get wikipedia embeddings loaded\n",
        "import torch\n",
        "from rag_wiki import rag\n",
        "\n",
        "print(\"torch.cuda.is_available()\", torch.cuda.is_available())\n",
        "print(torch.__version__)\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "dataset = rag.load_wiki_dataset(num_examples=1000, debug=True)\n",
        "print(\"Loading dataset...done\")\n",
        "print(\"\")\n",
        "\n",
        "# Preprocess the dataset\n",
        "print(\"Preprocessing dataset...\")\n",
        "index, texts = rag.preprocess(dataset, batch_size=200, debug=True)\n",
        "print(\"Preprocessing dataset...done\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "d6BGvIuzwVI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yIfTxzTdSlqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "def get_gpt2_model():\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n",
        "    #.to(device)\n",
        "    return model, tokenizer\n",
        "model, tokenizer = get_gpt2_model()"
      ],
      "metadata": {
        "id": "q6bOKGbsGMJD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, prompt, max_length=50, device=device):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    outputs = model.generate(input_ids,\n",
        "                             #.to(device),\n",
        "                             max_length=10000,\n",
        "                             do_sample=True,\n",
        "                             num_beams=3,\n",
        "                             temperature=0.7,\n",
        "                             no_repeat_ngram_size=2,\n",
        "                             early_stopping=True,\n",
        "                             eos_token_id=tokenizer.encode(\".\")[0])\n",
        "\n",
        "    # Decode the generated sequence back to text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "shjK3eEiGMlO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the index and retrieve relevant texts\n",
        "TOP_K_TEXTS = 2\n",
        "prompts = [\"What is the capital of India?\",\n",
        "           \"Who is the president of the United States?\",\n",
        "           \"What is the population of China?\",\n",
        "           \"The captial of France is \",\n",
        "           \"Where is the Eiffel Tower located?\"]\n",
        "prompts = [\"how long was i love lucy on the air\",\n",
        "           \"how did apollo creed die\",\n",
        "           \"how much is 1 tablespoon of water\",\n",
        "           \"how much are the harry potter movies worth\"]\n",
        "\n",
        "print(\"Retrieving relevant texts...\")\n",
        "print(\"Length of texts = \", len(texts))\n",
        "retrieved_texts = rag.retrieve(prompts, index, texts, top_k=TOP_K_TEXTS, debug=False)\n",
        "print(\"Retrieving relevant texts...done\")\n",
        "print(\"\")\n",
        "\n",
        "for p, ts in zip(prompts, retrieved_texts):\n",
        "    print(f\"Prompt: {p}\")\n",
        "    print(f\"Retrieved texts: {len(ts)}\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJRQO7v0107e",
        "outputId": "c3b0d44d-3354-42f2-cec6-316a8a7408e8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving relevant texts...\n",
            "Length of texts =  1040\n",
            "Retrieving relevant texts...done\n",
            "\n",
            "Prompt: how long was i love lucy on the air\n",
            "Retrieved texts: 2\n",
            "\n",
            "Prompt: how did apollo creed die\n",
            "Retrieved texts: 2\n",
            "\n",
            "Prompt: how much is 1 tablespoon of water\n",
            "Retrieved texts: 2\n",
            "\n",
            "Prompt: how much are the harry potter movies worth\n",
            "Retrieved texts: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in prompts:\n",
        "    print(\"Prompt: \", p)\n",
        "    print(\"----\")\n",
        "    print(generate_text(model, tokenizer, p))\n",
        "    print(\"=====\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "yVgEXTtgGdIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655b1bea-d565-43d2-fcdf-10590ff59356"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:  how long was i love lucy on the air\n",
            "----\n",
            "how long was i love lucy on the air, t on a on t the e on n on d on on w on o on r on g on h on e the on b on l on i on s on y on , on air.\n",
            "=====\n",
            "\n",
            "Prompt:  how did apollo creed die\n",
            "----\n",
            "how did apollo creed die out?\"\n",
            "\n",
            "\"No, it didn't.\n",
            "=====\n",
            "\n",
            "Prompt:  how much is 1 tablespoon of water\n",
            "----\n",
            "how much is 1 tablespoon of water and 1/2 teaspoon of sugar in a large bowl?\n",
            "\n",
            "The answer is no.\n",
            "=====\n",
            "\n",
            "Prompt:  how much are the harry potter movies worth\n",
            "----\n",
            "how much are the harry potter movies worth?\"\n",
            "\n",
            "\"No, I don't think so.\n",
            "=====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepend = \"Based on the information provided, answer the question concisely. Do not repeat the prompt.\"\n",
        "section1 = \"[INFO]\"\n",
        "section2 = \"[QUESTION]\"\n",
        "section3 = \"[ANSWER]\"\n",
        "qa_prompt_with_context = [prepend + \"\\n\" + section1 + \"\\n\" + \"\\n\".join(ts)[:1000] + \"\\n\" + section2 + \"\\n\" + p + \"\\n\" + section3 + \"\\n\" for p, ts in zip(prompts, retrieved_texts)]\n",
        "\n",
        "for p in qa_prompt_with_context:\n",
        "    print(\"Prompt: \", p)\n",
        "    print(\"----\")\n",
        "    print(generate_text(model, tokenizer, p))\n",
        "    print(\"=====\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv7BIwqU9T5O",
        "outputId": "4941fa31-3b3f-4bd8-83bf-94af09ffe088"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC television sketch comedy series Saturday Night Live (SNL) from 1986 to 1992.\n",
            "who played guitar on the kiss album, creatures of the night It is also the band's last album recorded with Ace Frehley credited as an official member (until 1998's Psycho Circus ), and its first album with Vinnie Vincent as the initially uncredited lead guitarist (Vincent would later be credited, but not featured pictorially on the cover, of 1985's reissue of the album ).\n",
            "[QUESTION]\n",
            "how long was i love lucy on the air\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC television sketch comedy series Saturday Night Live (SNL) from 1986 to 1992.\n",
            "who played guitar on the kiss album, creatures of the night It is also the band's last album recorded with Ace Frehley credited as an official member (until 1998's Psycho Circus ), and its first album with Vinnie Vincent as the initially uncredited lead guitarist (Vincent would later be credited, but not featured pictorially on the cover, of 1985's reissue of the album ).\n",
            "[QUESTION]\n",
            "how long was i love lucy on the air\n",
            "[ANSWER]\n",
            "I love it so much that I can't remember.\n",
            "=====\n",
            "\n",
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\n",
            "how was the moon formed Although there have been several hypotheses for its origin in the past, the current most widely accepted explanation is that the Moon formed from the debris left over after a giant impact between Earth and a Mars -sized body.\n",
            "[QUESTION]\n",
            "how did apollo creed die\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\n",
            "how was the moon formed Although there have been several hypotheses for its origin in the past, the current most widely accepted explanation is that the Moon formed from the debris left over after a giant impact between Earth and a Mars -sized body.\n",
            "[QUESTION]\n",
            "how did apollo creed die\n",
            "[ANSWER]\n",
            "The Apollo Creed was written by a man named Phil Plait.\n",
            "=====\n",
            "\n",
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\n",
            "how much is 1 tablespoon of water In the USA one tablespoon (measurement unit) is approximately 15 mL; the capacity of an actual tablespoon (dining utensil) ranges from 7 mL to 14 mL.\n",
            "[QUESTION]\n",
            "how much is 1 tablespoon of water\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\n",
            "how much is 1 tablespoon of water In the USA one tablespoon (measurement unit) is approximately 15 mL; the capacity of an actual tablespoon (dining utensil) ranges from 7 mL to 14 mL.\n",
            "[QUESTION]\n",
            "how much is 1 tablespoon of water\n",
            "[ANSWER]\n",
            "How much water is in a cup of coffee? How much does it take to make 1/2 cup (1 cup) of tea?\n",
            "What is the amount of sugar in the cup? What does the sugar taste like? Do you know how much sugar you need to drink to get the correct amount? If you do not know the answer to this question, then you are missing out on something important.\n",
            "=====\n",
            "\n",
            "Prompt:  Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\n",
            "who is the actor that plays harry potter Daniel Radcliffe , who portrays Harry Potter , has been the icon of the film series since the release of the first film in 2001.\n",
            "[QUESTION]\n",
            "how much are the harry potter movies worth\n",
            "[ANSWER]\n",
            "\n",
            "----\n",
            "Based on the information provided, answer the question concisely. Do not repeat the prompt.\n",
            "[INFO]\n",
            "how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\n",
            "who is the actor that plays harry potter Daniel Radcliffe , who portrays Harry Potter , has been the icon of the film series since the release of the first film in 2001.\n",
            "[QUESTION]\n",
            "how much are the harry potter movies worth\n",
            "[ANSWER]\n",
            "The series is based on a series of novels written by the author, and is set in the 1950s and 1960s.\n",
            "=====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_with_context = [\" \".join(ts)[:200] + \"\\n\" + p for p, ts in zip(prompts, retrieved_texts)]\n",
        "\n",
        "for p in prompt_with_context:\n",
        "    print(\"Prompt: \", p)\n",
        "    print(\"----\")\n",
        "    print(generate_text(model, tokenizer, p))\n",
        "    print(\"=====\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "pQVZuyLqGHHq",
        "outputId": "44248176-b446-498f-c2fd-2f165d250f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts with contexts:  ['who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC t\\nhow long was i love lucy on the air', 'how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\\nhow did apollo creed die', 'how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\\nhow much is 1 tablespoon of water', 'how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\\nhow much are the harry potter movies worth']\n",
            "Prompt:  who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC t\n",
            "how long was i love lucy on the air\n",
            "----\n",
            "who is victoria jackson from saturday night live Victoria Jackson (born August 2, 1959) is an American comedian, actress, satirist, singer and internet blogger best known as a cast member of the NBC t\n",
            "how long was i love lucy on the air?\n",
            "\n",
            "How long did it take you to find out that you were pregnant with your first child? How did you decide to have a baby? What was the most difficult decision you had to make? Did you have any regrets about your decision? Do you regret having a child now that your baby is born? Have you ever regretted having an abortion? If so, what do you think of it? Let us know your thoughts in the comments below!\n",
            "\n",
            "\n",
            "Share this: Facebook\n",
            "A new study from the University of California, San Diego (UCSD) and the National Institutes of Health (NIH) found that people who have been diagnosed with schizophrenia or bipolar disorder are more likely to be obese than those who are not.\n",
            "=====\n",
            "\n",
            "Prompt:  how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\n",
            "how did apollo creed die\n",
            "----\n",
            "how was the moon formed The Moon is thought to have formed nearly 4.5 billion years ago, not long after the Earth.\n",
            "how did apollo creed die out The Apollo 11 astronauts were killed in a plane crash in 1969.\n",
            "=====\n",
            "\n",
            "Prompt:  how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\n",
            "how much is 1 tablespoon of water\n",
            "----\n",
            "how much is 1 tablespoon of water This tablespoon has a capacity of about 15 mL.\n",
            "how much is 1 tablespoon of water 1 teaspoon of salt This teaspoon is about 1/4 teaspoon.\n",
            "=====\n",
            "\n",
            "Prompt:  how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\n",
            "how much are the harry potter movies worth\n",
            "----\n",
            "how much are the harry potter movies worth The series also originated much tie-in merchandise, making the Harry Potter brand worth in excess of $15 billion.\n",
            "how much are the harry potter movies worth\n",
            "\n",
            "The Potter series is the world's most popular television series, with more than 1.\n",
            "=====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEw7FK9o8gYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}