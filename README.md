# interp

A collection of interpretability colabs for tracing how LLMs store and retrieve facts to answer factual queries.

Interpretability and visualization: These colabs were heavily inspired/derived from other pre-written colabs. Appropriate credits and links are given to original work in these colabs.

  - Causal tracing of handcrafted prompts: cs230_visualization_causal_trace.ipynb
  - Logit Lens for handcrafted prompts: cs230_visualization_logit_lens.ipynb
  - Attention visualization cs230_visualizing_attention.ipynb


Measurement and rectification: These colabs use ashweta1/llm_fact_acc and ashweta1/rag_wiki libraries respectively. Appropriate commands to install these libraies are in the colab.

  - Measuring factual accuracy: cs230_measuring_llm_factual_accuracy.ipynb
  - Rectifying facts for factual accuracy using RAG: cs230_rectifying_facts_RAG.ipynb

